import numpy as np
import pandas as pd
import streamlit as st
from functions import *
import matplotlib.pyplot as plt
import networkx as nx
import re
from networkx.exception import PowerIterationFailedConvergence

### Streamlit êµ¬í˜„
def main():
    st.sidebar.header("ë‹¤ìš´ë¡œë“œ")
    st.title("ì‚°ì—…ì—°ê´€ë°ì´í„° DashBoard")
    mode = st.radio('ëª¨ë“œ ì„ íƒ', ['Korea(2010~2020)', 'Korea(1990~2005)', 'Manual'])
    if mode == 'Korea(2010~2020)':
        first_idx = (6,2)
        subplus_edit =False
        number_of_label = 2
    elif mode == 'Korea(1990~2005)':
        first_idx = (5,2)
        subplus_edit =True
        number_of_label = 2
    else:
        first_idx = 0
        subplus_edit =False
        number_of_label = 2

    if 'number_of_divide' not in st.session_state:
        st.session_state['number_of_divide'] = 0

    if "ids_simbol" not in st.session_state:
        st.session_state.ids_simbol = {}

    if "show_edited" not in st.session_state:
        st.session_state.show_edited = False
    if "edit_ops" not in st.session_state:
        st.session_state["edit_ops"] = [] 

    def _k(x):
        return int(x) if x.isdigit() else x
        
    def find_string_values(df, first_idx):
        # íŠ¹ì • êµ¬ê°„ì˜ ë°ì´í„° ì„ íƒ
        selected_df = df.iloc[first_idx[0]:, first_idx[1]:]

        # ë¬¸ìì—´ì´ í¬í•¨ëœ ì…€ì˜ ìœ„ì¹˜ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
        string_locations = []

        # ëª¨ë“  ì…€ì„ ìˆœíšŒí•˜ë©° ë¬¸ìì—´ì´ ìˆëŠ”ì§€ í™•ì¸
        for row_idx, row in selected_df.iterrows():
            for col_idx, value in row.items():
                if isinstance(value, str):  # ë¬¸ìì—´ì¸ì§€ í™•ì¸
                    string_locations.append((row_idx, col_idx, value))

        return string_locations
    # ë¬¸ìì—´ì´ í¬í•¨ëœ ìœ„ì¹˜ë¥¼ NAë¡œ ëŒ€ì²´í•˜ëŠ” í•¨ìˆ˜
    def replace_string_with_na(df, string_locations):
        for row_idx, col_idx, _ in string_locations:
            df.iloc[row_idx, col_idx] = np.nan  # í•´ë‹¹ ìœ„ì¹˜ì˜ ê°’ì„ pd.NAë¡œ ëŒ€ì²´

    def slice_until_first_non_nan_row(df):
        # DataFrameì˜ ë§¨ ì•„ë˜ë¶€í„° ìœ„ë¡œ ìˆœíšŒí•˜ë©° NaNì´ ì•„ë‹Œ ì²« ë²ˆì§¸ í–‰ ì°¾ê¸°
        last_valid_index = None
        for row_idx in reversed(range(df.shape[0])):  # ì•„ë˜ì—ì„œ ìœ„ë¡œ ìˆœíšŒ
            if not df.iloc[row_idx].isna().all():  # NaNì´ ì•„ë‹Œ í–‰ì„ ì°¾ìœ¼ë©´
                last_valid_index = row_idx
                break

        # NaNì´ ì•„ë‹Œ í–‰ê¹Œì§€ ìŠ¬ë¼ì´ì‹± (ì°¾ì§€ ëª»í•œ ê²½ìš° ì „ì²´ ìŠ¬ë¼ì´ìŠ¤)
        if last_valid_index is not None:
            sliced_df = df.iloc[:last_valid_index + 1]
        else:
            sliced_df = pd.DataFrame()  # ëª¨ë“  í–‰ì´ NaNì¸ ê²½ìš° ë¹ˆ DataFrame ë°˜í™˜

        return sliced_df, last_valid_index


    # íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜s
    st.session_state['uploaded_file'] = st.file_uploader("ì—¬ê¸°ì— íŒŒì¼ì„ ë“œë˜ê·¸í•˜ê±°ë‚˜ í´ë¦­í•˜ì—¬ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=['xls', 'xlsx'])
    if 'df' not in st.session_state:
        if st.session_state['uploaded_file']:
            st.write(st.session_state['uploaded_file'].name)
            st.session_state['df'] =load_data(st.session_state.uploaded_file, 0)
            st.session_state['df_local'] =load_data(st.session_state.uploaded_file, 1)
            #st.session_state['df'].iloc[first_idx[0]:, first_idx[1]:].replace(' ', pd.NA, inplace=True)
            #st.session_state['df'].iloc[first_idx[0]:, first_idx[1]:].dropna(inplace = True)
            # ë¬¸ìì—´ì´ í¬í•¨ëœ ìœ„ì¹˜ ì°¾ê¸°
            string_values = find_string_values(st.session_state['df'], first_idx)
            string_values_local = find_string_values(st.session_state['df_local'], first_idx)
            # ë¬¸ìì—´ì´ í¬í•¨ëœ ê°’ì„ NAë¡œ ëŒ€ì²´
            replace_string_with_na(st.session_state['df'], string_values)
            replace_string_with_na(st.session_state['df_local'], string_values_local)
            # ì‚¬ìš© ì˜ˆì‹œ
            st.session_state['df'], last_valid_index = slice_until_first_non_nan_row(st.session_state['df'])
            st.write(string_values)

            st.session_state['df_local'], last_valid_index = slice_until_first_non_nan_row(st.session_state['df_local'])
            st.write(string_values_local)

            st.session_state['mid_ID_idx'] = get_mid_ID_idx(st.session_state['df'], first_idx)
            st.session_state['mid_ID_idx_local'] = get_mid_ID_idx(st.session_state['df_local'], first_idx)

            st.session_state['df'].iloc[first_idx[0]:, first_idx[1]:] = st.session_state['df'].iloc[first_idx[0]:, first_idx[1]:].apply(pd.to_numeric, errors='coerce')
            st.session_state['df_local'].iloc[first_idx[0]:, first_idx[1]:] = st.session_state['df_local'].iloc[first_idx[0]:, first_idx[1]:].apply(pd.to_numeric, errors='coerce')
            if subplus_edit:
                st.session_state['df']=st.session_state['df'].iloc[:-1]

    if 'df' in st.session_state:
        uploaded_matrix_X = get_submatrix_withlabel(st.session_state['df'], first_idx[0], first_idx[1], st.session_state['mid_ID_idx'][0], st.session_state['mid_ID_idx'][1], first_idx, numberoflabel=number_of_label)
        uploaded_matrix_R = get_submatrix_withlabel(st.session_state['df'], st.session_state['mid_ID_idx'][0]+1, first_idx[1], st.session_state['df'].shape[0]-1, st.session_state['mid_ID_idx'][1], first_idx, numberoflabel=number_of_label)
        uploaded_matrix_C = get_submatrix_withlabel(st.session_state['df'], first_idx[0], st.session_state['mid_ID_idx'][1]+1, st.session_state['mid_ID_idx'][0], st.session_state['df'].shape[1]-1, first_idx, numberoflabel=number_of_label)

        uploaed_files = {
        "uploaded_df": st.session_state['df'],
        "uploaded_matrix_X": uploaded_matrix_X,
        "uploaded_matrix_R": uploaded_matrix_R,
        "uploaded_matrix_C": uploaded_matrix_C
                                }
        with st.sidebar.expander("ìµœì´ˆ ì—…ë¡œë“œ ì›ë³¸ íŒŒì¼"):
            download_multiple_csvs_as_zip(uploaed_files, zip_name="ìµœì´ˆ ì—…ë¡œë“œ ì›ë³¸ íŒŒì¼ ì „ì²´(zip)")
            donwload_data(st.session_state['df'], 'uploaded_df')
            donwload_data(uploaded_matrix_X, 'uploaded_matrix_X')
            donwload_data(uploaded_matrix_R, 'uploaded_matrix_R')
            donwload_data(uploaded_matrix_C, 'uploaded_matrix_C')
        # ì›ë³¸ ë¶€ë¶„ header í‘œì‹œ
        st.header('ìµœì´ˆ ì—…ë¡œë“œ ëœ ExcelíŒŒì¼ ì…ë‹ˆë‹¤.')
        # ë°ì´í„°í”„ë ˆì„ í‘œì‹œ 
        tab1, tab2, tab3, tab4 = st.tabs(['uploaded_df', 'uploaded_matrix_X', 'uploaded_matrix_R', 'uploaded_matrix_C'])
        with tab1:
            st.write(st.session_state['df'])
        with tab2:
            st.write(uploaded_matrix_X)
        with tab3:
            st.write(uploaded_matrix_R)
        with tab4:
            st.write(uploaded_matrix_C)

        if 'df_editing' not in st.session_state:
            st.session_state['df_editing'] = st.session_state['df'].copy()
            st.session_state['df_editing_local'] = st.session_state['df_local'].copy()
            col = first_idx[1] - number_of_label                 # ë¼ë²¨ ì—´ ìœ„ì¹˜
            s   = st.session_state['df_editing'].iloc[:, col]    # í•´ë‹¹ ì—´ Series

            # â”€â”€ â‘  float64 â†’ Int64(ì •ìˆ˜, NaN í—ˆìš©) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if pd.api.types.is_float_dtype(s):
                s = s.astype('Int64')        # 1.0 â†’ 1,  NaN ê·¸ëŒ€ë¡œ ìœ ì§€
                s = s.astype('string')        # 1.0 â†’ 1,  NaN ê·¸ëŒ€ë¡œ ìœ ì§€
                st.session_state['df_editing'].iloc[:, col] = s.astype('object') 
                st.session_state['df_editing_local'].iloc[:, col] = s.astype('object') 

    if 'data_editing_log' not in st.session_state:
        st.session_state['data_editing_log'] = ''

    if 'df_editing' in st.session_state:
        st.header("DataFrameì„ ìˆ˜ì •í•©ë‹ˆë‹¤.")
        st.markdown("#### ìë™ ì…ë ¥ ì²˜ë¦¬ (ì—‘ì…€ íŒŒì¼ë¡œ ì¼ê´„ ì²˜ë¦¬)")
        
        # =========================
        # Batch Processing (ì—…ë¡œë“œ ì¦‰ì‹œ ì¤€ë¹„ -> í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸° -> ì ìš© ë²„íŠ¼)
        # =========================
        alpha_file = st.file_uploader("Alpha ê°’ ì—‘ì…€/ZIP íŒŒì¼ ì—…ë¡œë“œ", type=["xlsx", "xls", "zip"])

        if alpha_file:
            # ì›ë³¸ ì—…ë¡œë“œ íŒŒì¼ëª…(í™•ì¥ì ì œì™¸) - ZIP ë§¤ì¹­ì—ë§Œ ì‚¬ìš©
            original_filename_no_ext = st.session_state["uploaded_file"].name.rsplit(".", 1)[0]

            # ì—…ë¡œë“œ íŒŒì¼ ë³€ê²½ ê°ì§€ (rerunì—ì„œë„ ì¤‘ë³µ ì¤€ë¹„ ë°©ì§€)
            alpha_key = (alpha_file.name, len(alpha_file.getvalue()))
            if st.session_state.get("alpha_key") != alpha_key:
                st.session_state["alpha_key"] = alpha_key

                # ì—…ë¡œë“œ ì¦‰ì‹œ 1ë‹¨ê³„+2ë‹¨ê³„ ìë™ ìˆ˜í–‰
                try:
                    batch_df_clean, meta, preview_lines, summary_lines = prepare_batch_preview(
                        alpha_file, original_filename_no_ext
                    )
                    st.session_state["batch_df_clean"] = batch_df_clean
                    st.session_state["batch_meta"] = meta
                    st.session_state["batch_preview_lines"] = preview_lines
                except Exception as e:
                    st.session_state["batch_df_clean"] = None
                    st.error(f"ë¯¸ë¦¬ë³´ê¸° ì¤€ë¹„ ì¤‘ ì˜¤ë¥˜: {e}")

            # --- 2ë‹¨ê³„: í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸° ì¶œë ¥ ---
            if st.session_state.get("batch_df_clean") is not None:
                st.markdown("##### ì¼ê´„ ì ìš© ë‚´ì—­ ìš”ì•½")
                df_prev = st.session_state["batch_df_clean"].copy()
                df_prev["from"] = df_prev["from"].astype(str)
                df_prev["to"]   = df_prev["to"].astype(str)
                df_prev["to_name"] = df_prev["to_name"].astype(str).replace("nan", "").fillna("")

                # to -> from ìˆœ ì •ë ¬ ( _këŠ” ìœ„ì—ì„œ ì •ì˜/ì´ë™ëœ í•¨ìˆ˜ ì‚¬ìš© )
                df_prev = df_prev.sort_values(by=["to", "from"], key=lambda s: s.map(_k))

                # toë³„ ê·¸ë£¹ ì¶œë ¥ (ê·¸ë£¹í‚¤ëŠ” to ì½”ë“œë¡œ ìœ ì§€)
                for idx, (to_code, g) in enumerate(df_prev.groupby("to", sort=False), start=1):
                    # âœ… í‘œì‹œìš© ì´ë¦„: ê·¸ë£¹ ë‚´ to_name ê³ ìœ ê°’
                    names = [n for n in g["to_name"].dropna().unique().tolist() if n and n != "None"]
                    if len(names) == 0:
                        display_name = to_code
                    elif len(names) == 1:
                        display_name = names[0]
                    else:
                        display_name = f"{names[0]} ì™¸ {len(names)-1}"

                    st.markdown(f"**[{idx}: {display_name}]**")

                    lines = [
                        f"{r['from']} -> {r['to']} : {float(r['alpha'])*100:.4f}%"
                        for _, r in g.iterrows()
                    ]
                    for i in range(0, len(lines), 5):
                        st.write(" | ".join(lines[i:i+5]))


                # --- 3ë‹¨ê³„: ì ìš© ë²„íŠ¼ ëˆ„ë¥´ë©´ ì‹¤ì œ ì—…ë°ì´íŠ¸ ì‹¤í–‰ ---
                if st.button("ì¼ê´„ ì ìš©"):
                    try:
                        batch_df = st.session_state["batch_df_clean"]

                        df_new, mid_new, ids_new, log_msg = apply_batch_edit(
                            batch_df=batch_df,
                            df_curr=st.session_state["df_editing"],
                            first_idx=first_idx,
                            number_of_label=number_of_label,
                            mid_ID_idx=st.session_state["mid_ID_idx"],
                            ids_simbol=st.session_state.ids_simbol,
                            insert_row_and_col_fn=insert_row_and_col,
                        )

                        st.session_state["df_editing"] = df_new
                        st.session_state["mid_ID_idx"] = mid_new
                        st.session_state.ids_simbol = ids_new

                        # ë°”ê¹¥ì—ì„œ ë¡œê·¸ ëˆ„ì 
                        st.session_state["data_editing_log"] += (log_msg + "\n\n")

                        # ops ì—”ì§„ ê¸°ë¡
                        st.session_state["edit_ops"].append({
                             "type": "batch_apply",
                             "batch_records": batch_df.to_dict("records")
                         })

                        st.session_state.show_edited = False
                        st.rerun()

                    except Exception as e:
                        st.error(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        # Manual Processing (Existing)
        st.markdown("#### ìˆ˜ë™ ì…ë ¥")
        col1, col2, col3 = st.columns(3)
        with col1:
            new_code = st.text_input('ìƒˆë¡œ ì‚½ì…í•  ì‚°ì—…ì˜ codeë¥¼ ì…ë ¥í•˜ì„¸ìš”')
        with col2:
            name = st.text_input('ìƒˆë¡œ ì‚½ì…í•  ì‚°ì—…ì˜ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”')
        with col3:
            if st.button('ì‚°ì—… ì¶”ê°€'):
                result = insert_row_and_col(st.session_state['df_editing'], first_idx, st.session_state['mid_ID_idx'], new_code, name, number_of_label)
                st.session_state['df_editing'], st.session_state['mid_ID_idx'] = result[0:2]
                st.session_state['data_editing_log'] += (result[2] + '\n\n')
                if new_code not in st.session_state.ids_simbol:
                    st.session_state.ids_simbol[new_code] = []  # ìƒˆë¡œìš´ ë¦¬ìŠ¤íŠ¸ ìƒì„±
                st.session_state.ids_simbol[new_code].append(name)  # ê°’ ì¶”ê°€
                st.session_state.show_edited = False

                st.session_state["edit_ops"].append({
                "type": "insert_sector",
                "code": str(new_code),
                "name": str(name),
                })

        col1, col2, col3, col4 = st.columns(4)
        with col1:
            origin_code = st.text_input('from')
        with col2:
            target_code = st.text_input('to')
        with col3:
            alpha = float(st.text_input('alpha value (0.000 to 1.000)', '0.000'))
        with col4:
            if st.button('ê°’ ì˜®ê¸°ê¸°'):
                result = transfer_to_new_sector(st.session_state['df_editing'], first_idx, origin_code, target_code, alpha)
                st.session_state['df_editing'] = result[0]
                st.session_state['data_editing_log'] += (result[1] + '\n\n')

                st.session_state["edit_ops"].append({
                    "type": "transfer",
                    "from": str(origin_code),
                    "to": str(target_code),
                    "alpha": float(alpha),
                })
                st.session_state.show_edited = False
        col1, col2, col3 = st.columns(3)
        with col1:
            if st.button('0ì¸ í–‰(ì—´) ì‚­ì œ'):
                result = remove_zero_series(st.session_state['df_editing'], first_idx, st.session_state['mid_ID_idx'])
                st.session_state['df_editing'] = result[0]
                st.session_state['data_editing_log'] += (result[1] + '\n\n')
                st.session_state['mid_ID_idx'] = result[2]

                st.session_state["edit_ops"].append({"type": "remove_zero"})
                st.session_state.show_edited = False
        with col2:
             if st.button('-ê°’ ì ˆë°˜ìœ¼ë¡œ ì¤„ì´ê¸°'):
                mid_ID_idx_reduced = (st.session_state['mid_ID_idx'][0] - 1, st.session_state['mid_ID_idx'][1] - 1)
                result = reduce_negative_values(st.session_state['df_editing'], first_idx, mid_ID_idx_reduced)
                st.session_state['df_editing'] = result[0]
                st.session_state['data_editing_log'] += (result[1] + '\n\n')
                st.session_state['number_of_divide'] +=1

                st.session_state["edit_ops"].append({"type": "reduce_negative", "use_minus_one_mid": True})
                st.session_state.show_edited = False
        with col3:
            if st.button('ì „ì²´ ì ìš©'):
                st.session_state['df_edited'] = st.session_state['df_editing'].copy()
                st.session_state.show_edited = True
                
                if "df_local" in st.session_state:
                    df_local_new, mid_local_new, ids_local_new = replay_edit_ops_on_df(
                        df_base=st.session_state["df_editing_local"],
                        mid_ID_idx_base=st.session_state["mid_ID_idx_local"],
                        ids_simbol_base=st.session_state.ids_simbol,   # ê³µìœ  ì‹«ìœ¼ë©´ local dict ë”°ë¡œ ë‘ê¸°
                        ops=st.session_state["edit_ops"],
                        first_idx=first_idx,
                        number_of_label=number_of_label,
                        insert_row_and_col_fn=insert_row_and_col,
                        transfer_to_new_sector_fn=transfer_to_new_sector,
                        remove_zero_series_fn=remove_zero_series,
                        reduce_negative_values_fn=reduce_negative_values,
                        return_log=False,
                        batch_apply_fn=apply_batch_edit
                    )
                    st.session_state["df_editing_local"] = df_local_new
                    st.session_state["mid_ID_idx_local"] = mid_local_new

                    st.session_state["df_edited_local"] = st.session_state['df_editing_local'].copy()

                # 3) âœ… pending ops ë¹„ìš°ê¸°(ì¤‘ë³µ ì ìš© ë°©ì§€)
                st.session_state["edit_ops"] = []
        st.markdown(f"##### - ê°’ ë‚˜ëˆ„ëŠ” ê²ƒ: **{st.session_state['number_of_divide']}** ë²ˆ ì ìš©")
        st.write(st.session_state['df_editing'])

    if 'df_edited' in st.session_state and st.session_state.show_edited:
        st.header('ìœ„ì—ì„œ ìˆ˜ì • ëœ ExcelíŒŒì¼ ì…ë‹ˆë‹¤.')
        edited_matrix_X = get_submatrix_withlabel(st.session_state['df_edited'], first_idx[0],first_idx[1], st.session_state['mid_ID_idx'][0], st.session_state['mid_ID_idx'][1], first_idx, numberoflabel = 2)
        edited_matrix_X_local = get_submatrix_withlabel(st.session_state['df_edited_local'], first_idx[0],first_idx[1], st.session_state['mid_ID_idx_local'][0], st.session_state['mid_ID_idx_local'][1], first_idx, numberoflabel = 2)
        edited_matrix_R = get_submatrix_withlabel(st.session_state['df_edited'], st.session_state['mid_ID_idx'][0]+1,first_idx[1], st.session_state['df_edited'].shape[0]-1, st.session_state['mid_ID_idx'][1], first_idx, numberoflabel = 2)
        edited_matrix_C = get_submatrix_withlabel(st.session_state['df_edited'], first_idx[0], st.session_state['mid_ID_idx'][1]+1, st.session_state['mid_ID_idx'][0], st.session_state['df_edited'].shape[1]-1, first_idx, numberoflabel = 2)
        edited_files = {
        "edited_df": st.session_state['df_edited'],
        "edited_matrix_X": edited_matrix_X,
        "edited_matrix_R": edited_matrix_R,
        "edited_matrix_C": edited_matrix_C
                                }
        with st.sidebar.expander("ìˆ˜ì •ëœ íŒŒì¼"):
            download_multiple_csvs_as_zip(edited_files, zip_name="ìˆ˜ì •ëœ íŒŒì¼ ì „ì²´(zip)")
            donwload_data(st.session_state['df_edited'], 'edited_df')
            donwload_data(edited_matrix_X, 'edited_matrix_X')
            donwload_data(edited_matrix_R, 'edited_matrix_R')
            donwload_data(edited_matrix_C, 'ueditedmatrix_C')
        # ë°ì´í„°í”„ë ˆì„ í‘œì‹œ
        tab1, tab2, tab3, tab4 = st.tabs(['edited_df', 'edited_matrix_X', 'edited_matrix_R', 'edited_matrix_C'])

        with tab1:
            st.write(st.session_state['df_edited'])

        with tab2:
            st.write(edited_matrix_X)

        with tab3:
            st.write(edited_matrix_R)

        with tab4:
            st.write(edited_matrix_C)

    if 'df_edited' in st.session_state and st.session_state.show_edited:
        st.session_state['df_for_leontief'] = edited_matrix_X.iloc[:-1, :-1].copy()
        st.session_state['df_for_leontief'].index = range(st.session_state['df_for_leontief'].shape[0])
        st.session_state['df_for_leontief'].columns = range(st.session_state['df_for_leontief'].shape[1])

        st.session_state['df_for_leontief_local'] = edited_matrix_X_local.iloc[:-1, :-1].copy()
        st.session_state['df_for_leontief_local'].index = range(st.session_state['df_for_leontief_local'].shape[0])
        st.session_state['df_for_leontief_local'].columns = range(st.session_state['df_for_leontief_local'].shape[1])

        st.session_state['df_for_r'] = edited_matrix_R.iloc[:-1, :-1].copy()
        st.session_state['df_for_r'].index = range(st.session_state['df_for_r'].shape[0])
        st.session_state['df_for_r'].columns = range(st.session_state['df_for_r'].shape[1])

        st.session_state['normalization_denominator'] = st.session_state['df_edited'].iloc[st.session_state['df_edited'].shape[0]-1, first_idx[1]:st.session_state['mid_ID_idx'][1]]
        st.session_state['normalization_denominator'] = pd.to_numeric(st.session_state['normalization_denominator'])
        st.session_state['normalization_denominator_replaced'] = st.session_state['normalization_denominator'].replace(0, np.finfo(float).eps)
        st.session_state['added_value_denominator'] = st.session_state['df_edited'].iloc[st.session_state['df_edited'].shape[0] - 2, first_idx[1]:st.session_state['mid_ID_idx'][1]]
        st.session_state['added_value_denominator'] = pd.to_numeric(st.session_state['added_value_denominator'])
        st.session_state['added_value_denominator_replaced'] = st.session_state['added_value_denominator'].replace(0, np.finfo(float).eps)

        st.session_state['added_value_denominator'] = st.session_state['df_edited'].iloc[st.session_state['df_edited'].shape[0] - 2, first_idx[1]:st.session_state['mid_ID_idx'][1]]
        st.session_state['added_value_denominator'] = pd.to_numeric(st.session_state['added_value_denominator'])
        st.session_state['added_value_denominator_replaced'] = st.session_state['added_value_denominator'].replace(0, np.finfo(float).eps)

        # 2025-12-26 ì¶”ê°€
        st.session_state['v'] = (st.session_state['added_value_denominator'] / st.session_state['normalization_denominator_replaced'])

        v_vec = st.session_state['v'].to_numpy()
        V_matrix = np.diag(v_vec)
        st.session_state['V'] = V_matrix

        # 1) ë‘ë²ˆì§¸ í–‰(= iloc[1])ì—ì„œ 'ìµœì¢…ìˆ˜ìš”ê³„' ì°¾ê¸°
        header2 = edited_matrix_C.iloc[1].fillna("").astype(str).str.strip()

        # ì •í™•íˆ ì¼ì¹˜ë¡œ ì°¾ê¸°
        pos = np.where(header2.values == "ìµœì¢…ìˆ˜ìš”ê³„")[0]
        if len(pos) == 0:
            # í˜¹ì‹œ ê³µë°±/í‘œê¸°ê°€ ë‹¤ë¥¸ ê²½ìš° ëŒ€ë¹„(ë¶€ë¶„ì¼ì¹˜)
            pos = np.where(header2.str.contains("ìµœì¢…ìˆ˜ìš”", na=False).values)[0]

        if len(pos) == 0:
            raise ValueError("edited_matrix_Cì˜ 2ë²ˆì§¸ í–‰ì—ì„œ 'ìµœì¢…ìˆ˜ìš”ê³„' ì—´ì„ ëª» ì°¾ì•˜ìŒ")

        col_pos = int(pos[0])  # 'ìµœì¢…ìˆ˜ìš”ê³„' ì—´ì˜ 'ìœ„ì¹˜(ì •ìˆ˜)'

        # 2) ì‚°ì—… í–‰ì€ iloc[2:]ë¶€í„° ì‹œì‘(ë¼ë²¨ 2í–‰ ì œê±°)
        st.session_state['y'] = pd.to_numeric(edited_matrix_C.iloc[2:, col_pos], errors="coerce").to_numpy().reshape(-1, 1)




        
    if 'df_for_leontief' in st.session_state and st.session_state.show_edited:
        st.session_state["df_for_local_leontief_with_label"] , st.session_state["df_for_local_leontief_without_label"]= build_leontief_outputs(
        st.session_state["df_for_leontief_local"],
        st.session_state["normalization_denominator_replaced"],
    ) # for local 

        st.session_state['df_for_leontief_with_label'] = st.session_state['df_for_leontief'].copy()
        st.session_state['df_for_leontief_without_label'] = st.session_state['df_for_leontief_with_label'].iloc[2:, 2:].copy()
        st.session_state['df_for_r_without_label'] = st.session_state['df_for_r'].iloc[2:, 2:].copy()
        st.session_state['df_for_r_with_label'] = st.session_state['df_for_r'].copy()
        
        tmp = st.session_state['df_for_leontief_without_label'].copy()
        tmp = tmp.apply(pd.to_numeric, errors='coerce')
        tmp = tmp.divide(st.session_state['normalization_denominator_replaced'], axis=1) ##d

        tmp2 = st.session_state['df_for_r_without_label'].copy()
        tmp2 = tmp2.apply(pd.to_numeric, errors='coerce')
        tmp2 = tmp2.divide(st.session_state['normalization_denominator_replaced'], axis=1) ##d
    
        st.session_state['df_for_leontief_with_label'].iloc[2:, 2:] = tmp
        st.session_state['df_for_r_with_label'].iloc[2:, 2:] = tmp2

        st.session_state['df_normalized_with_label'] = st.session_state['df_for_leontief_with_label'].copy()
        unit_matrix = np.eye(tmp.shape[0])
        subtracted_matrix = unit_matrix - tmp
        leontief = np.linalg.inv(subtracted_matrix.values)
        leontief = pd.DataFrame(leontief)
        # í˜„ì¬ DataFrameì„ ê°€ì ¸ì˜¤ê¸°
        current_df = st.session_state['df_for_leontief_with_label']

        # ê¸°ì¡´ DataFrameì—ì„œ 2í–‰ê³¼ 2ì—´ì„ ì œê±°í•œ í›„, í¬ê¸°ë¥¼ ì •ì˜
        existing_rows = current_df.shape[0] - 2  # ê¸°ì¡´ DataFrameì˜ í–‰ ìˆ˜
        existing_cols = current_df.shape[1] - 2  # ê¸°ì¡´ DataFrameì˜ ì—´ ìˆ˜

        # leontief ë°°ì—´ì˜ í¬ê¸°
        leontief_rows, leontief_cols = leontief.shape

        # ìƒˆë¡œìš´ DataFrame ìƒì„± (NaNìœ¼ë¡œ ì´ˆê¸°í™”)
        new_df = pd.DataFrame(np.nan, index=range(existing_rows + 1), columns=range(existing_cols + 1))

        # leontief ë°°ì—´ì´ ê¸°ì¡´ í¬ê¸°ì™€ ì¼ì¹˜í•  ë•Œ
        if leontief_rows == existing_rows and leontief_cols == existing_cols:
            # leontief ë°ì´í„°ë¥¼ ìƒˆë¡œìš´ DataFrameì˜ ì ì ˆí•œ ë¶€ë¶„ì— ì‚½ì…
            new_df.iloc[:existing_rows, :existing_cols] = leontief  # ê¸°ì¡´ ë°ì´í„° ë¶€ë¶„ì— í• ë‹¹

        # N*N ë°°ì—´ì—ì„œ N+1*N+1ë¡œ ë³€í™˜
        leontief_with_sums = np.zeros((leontief_rows + 1, leontief_cols + 1))
        leontief_with_sums[:-1, :-1] = leontief  # ê¸°ì¡´ leontief ë°°ì—´ì„ ë„£ê¸°
        leontief_with_sums[-1, :-1] = leontief.sum(axis=0)  # ë§ˆì§€ë§‰ í–‰ì— ê° ì—´ì˜ í•©
        leontief_with_sums[:-1, -1] = leontief.sum(axis=1)  # ë§ˆì§€ë§‰ ì—´ì— ê° í–‰ì˜ í•©

        # ë§ˆì§€ë§‰ í–‰ ê°’ë“¤ì„ ë§ˆì§€ë§‰ í–‰ í‰ê· ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
        last_row_mean = leontief_with_sums[-1, :-1].mean()  # ë§ˆì§€ë§‰ í–‰ í‰ê· 
        leontief_with_sums[-1, :-1] /= last_row_mean  # ë§ˆì§€ë§‰ í–‰ ë‚˜ëˆ„ê¸°

        # ë§ˆì§€ë§‰ ì—´ ê°’ë“¤ì„ ë§ˆì§€ë§‰ ì—´ í‰ê· ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
        last_col_mean = leontief_with_sums[:-1, -1].mean()  # ë§ˆì§€ë§‰ ì—´ í‰ê· 
        leontief_with_sums[:-1, -1] /= last_col_mean  # ë§ˆì§€ë§‰ ì—´ ë‚˜ëˆ„ê¸°

        # ìµœì¢…ì ìœ¼ë¡œ N+1*N+1 ë°°ì—´ì„ ìƒˆë¡œìš´ DataFrameì— ì—…ë°ì´íŠ¸
        # ìƒˆë¡œìš´ í¬ê¸°ë¡œ DataFrameì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        new_df = pd.DataFrame(leontief_with_sums)
        # ê¸°ì¡´ DataFrameì˜ í¬ê¸°ë¥¼ 1ì”© ëŠ˜ë¦¬ê¸° (NaNìœ¼ë¡œ ì´ˆê¸°í™”)
        current_df = current_df.reindex(index=range(existing_rows + 3), 
                                        columns=range(existing_cols + 3))


        # ìƒˆë¡œìš´ DataFrameì„ ê¸°ì¡´ DataFrameì˜ ì ì ˆí•œ ìœ„ì¹˜ì— ì—…ë°ì´íŠ¸
        current_df.iloc[2:2 + new_df.shape[0], 2:2 + new_df.shape[1]] = new_df
        current_df.iloc[1,-1]="FL"
        current_df.iloc[-1,1]="BL"
        # ì„¸ì…˜ ìƒíƒœì— ì—…ë°ì´íŠ¸
        st.session_state['df_for_leontief_with_label'] = current_df


        ids_col = st.session_state['df_for_leontief_with_label'].iloc[1:-1, :2]
        fl_data = st.session_state['df_for_leontief_with_label'].iloc[1:-1, -1]
        bl_data = st.session_state['df_for_leontief_with_label'].iloc[-1, 1:-1]
        
        # DataFrameìœ¼ë¡œ ë³€í™˜ (bl_dataê°€ Seriesì¼ ê²½ìš° dfë¡œ ë³€í™˜ í•„ìš”)
        fl_data = fl_data.to_frame(name="2")  # FL ì—´ ì´ë¦„ ì§€ì •
        bl_data = bl_data.to_frame(name="3")  # BL ì—´ ì´ë¦„ ì§€ì •

        # ì¸ë±ìŠ¤ë¥¼ ë¦¬ì…‹í•˜ì—¬ ë³‘í•©ì´ ê°€ëŠ¥í•˜ë„ë¡ ì •ë¦¬
        ids_col = ids_col.reset_index(drop=True)
        fl_data = fl_data.reset_index(drop=True)
        bl_data = bl_data.reset_index(drop=True)

        # ì¢Œìš°ë¡œ ë°ì´í„°í”„ë ˆì„ ê²°í•© (concat ì‚¬ìš©)
        st.session_state['fl_bl'] = pd.concat([ids_col, fl_data, bl_data], axis=1)

        st.session_state['df_for_leontief_with_label']=st.session_state['df_for_leontief_with_label'].iloc[:-1, :-1]
        st.session_state['df_for_leontief_without_label'] = st.session_state['df_for_leontief_with_label'].iloc[2:, 2:].copy()

        # 2025-12-26 ì¶”ê°€ (GDP ë° ë¶€ê°€ê°€ì¹˜ ìœ ë°œ íš¨ê³¼)
        # L, y, V ì¤€ë¹„
        L = st.session_state['df_for_leontief_without_label'].apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy()
        L_local = st.session_state['df_for_local_leontief_without_label'].apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy()
        y = np.asarray(st.session_state['y']).reshape(-1, 1)
        y = y[:-1, :] 

        V = st.session_state['V']
        v = np.asarray(st.session_state['v'], dtype=float).reshape(1, -1)


        # GDP ìƒì„±
        x = L @ y
        g = V @ x

        # ë¶€ê°€ê°€ì¹˜ ìœ ë°œ íš¨ê³¼
        m_v = v @ L_local


        # =========================
        # [A] GDP(ì‚°ì—…ë³„ VA ìœ ë°œì•¡)
        # =========================
        base_df = st.session_state['df_for_local_leontief_with_label']

        ids_col = base_df.iloc[1:, :2].reset_index(drop=True)  # ë¼ë²¨ì€ ê·¸ëŒ€ë¡œ(ì²« ë¼ë²¨í–‰ í¬í•¨ëœ êµ¬ì¡° ìœ ì§€)

        g_vec  = g.reshape(-1)
        g_data = pd.concat(
            [
                pd.DataFrame(["GDP"], columns=["2"]),
                pd.Series(g_vec).to_frame(name="2")
            ],
            axis=0
        ).reset_index(drop=True)

        st.session_state['gdp_by_industry'] = pd.concat([ids_col, g_data], axis=1)

        st.session_state['GDP_total'] = float(g_vec.sum())
        st.session_state['GDP_mean']  = float(g_vec.mean())



        # =========================
        # [B] ë¶€ê°€ê°€ì¹˜ ìœ ë°œíš¨ê³¼(m_v)
        # =========================
        ids_col = base_df.iloc[1:, :2].reset_index(drop=True)

        mv_vec  = m_v.reshape(-1)
        mv_data = pd.concat(
            [
                pd.DataFrame(["ë¶€ê°€ê°€ì¹˜ìœ ë°œíš¨ê³¼"], columns=["2"]),
                pd.Series(mv_vec).to_frame(name="2")
            ],
            axis=0
        ).reset_index(drop=True)

        st.session_state['va_multiplier_by_sector'] = pd.concat([ids_col, mv_data], axis=1)

        st.session_state['m_v_total'] = float(mv_vec.sum())
        st.session_state['m_v_mean']  = float(mv_vec.mean())





        st.subheader('Leontief ê³¼ì • matrices')
        col1, col2, col3, col4, col5, col6, col7, col8, col9= st.tabs(['edited_df', 'normailization denominator', 'íˆ¬ì…ê³„ìˆ˜í–‰ë ¬', 'leontief inverse','FL-BL','GDP','ë¶€ê°€ê°€ì¹˜ìœ ë°œíš¨ê³¼(êµ­ë‚´)','ë¶€ê°€ê°€ì¹˜ê³„ìˆ˜í–‰ë ¬','ë¶€ê°€ê°€ì¹˜ê³„ë²¡í„°'])
        with col1:
            st.write(st.session_state['df_for_leontief'])
        with col2:
            st.write(st.session_state['normalization_denominator'])
        with col3:
            st.write(st.session_state['df_normalized_with_label'])
        with col4:
            st.write(st.session_state['df_for_leontief_with_label'])
            invalid_positions = []
        with col5:
            st.write(st.session_state['fl_bl'])
        with col6:
            st.write(st.session_state['gdp_by_industry'])
            st.write("GDP_total (sum g):", st.session_state['GDP_total'])
            st.write("GDP_mean (mean g):", st.session_state['GDP_mean'])
        with col7:
            st.write(st.session_state['va_multiplier_by_sector'])
            st.write("m_v_total (sum m_v):", st.session_state['m_v_total'])
            st.write("m_v_mean (mean m_v):", st.session_state['m_v_mean'])
        with col8:
            st.write(st.session_state['df_for_r_with_label'])
        with col9:
            st.write(st.session_state['added_value_denominator'])

        st.subheader("ë ˆì˜¨í‹°ì—í”„ ì—­í–‰ë ¬ì„ í†µí•œ ì •í•©ì„± ê²€ì¦ ë‚´ìš©")
        is_equal_to_one_row = np.isclose(leontief_with_sums[-1, :-1].mean(), 1)
        st.write(f"í–‰(ì˜í–¥ë ¥ê³„ìˆ˜) í•©ì˜ í‰ê· ì´ 1ê³¼ ë™ì¼ ì—¬ë¶€ {is_equal_to_one_row}")
        is_equal_to_one_row = np.isclose(leontief_with_sums[:-1, -1].mean(), 1)
        st.write(f"ì—´(ê°ì‘ë„ê³„ìˆ˜) í•©ì˜ í‰ê· ì´ 1ê³¼ ë™ì¼ ì—¬ë¶€ {is_equal_to_one_row}")


        # 1. í–‰ë ¬ì„ ìˆœíšŒí•˜ë©° -0.1 ~ 2 ë²”ìœ„ë¥¼ ë²—ì–´ë‚œ ê°’ì˜ ìœ„ì¹˜ë¥¼ ì°¾ìŒ
        for i in range(leontief.shape[0]):
            for j in range(leontief.shape[1]):
                value = leontief.iloc[i, j]
                if not (-0.1 <= value <= 2):
                    invalid_positions.append((i + 2, j + 2, value))  # ìœ„ì¹˜ ì¡°ì • (+2)

        # 2. ëŒ€ê° ì›ì†Œ ì¤‘ 1 ì´í•˜ì¸ ê°’ì˜ ìœ„ì¹˜ì™€ ê°’ ì €ì¥
        diagonal_invalid_positions = []
        for i in range(leontief.shape[0]):
            value = leontief.iloc[i, i]
            if value < 1:
                diagonal_invalid_positions.append((i + 2, i + 2, value))  # ìœ„ì¹˜ ì¡°ì • (+2)

        # ê²°ê³¼ ì¶œë ¥
        if invalid_positions:
            st.write("ì¡°ê±´(-0.1 ~ 2.0)ì— ë§ì§€ ì•ŠëŠ” ìœ„ì¹˜ì™€ ê°’:")
            for pos in invalid_positions:
                st.write(f"ìœ„ì¹˜: {pos[:2]}, ê°’: {pos[2]}")
        else:
            st.write("ëª¨ë“  ê°’ì´ -0.1 ~ 2 ì‚¬ì´ì˜ ì¡°ê±´ì„ ë§Œì¡±í•©ë‹ˆë‹¤.")

        # ëŒ€ê° ì›ì†Œ ì¡°ê±´ í™•ì¸ ë° ê²°ê³¼ ì¶œë ¥
        if diagonal_invalid_positions:
            st.write("ëŒ€ê° ì›ì†Œ ì¤‘ 1 ë¯¸ë§Œì¸ ê°’ì´ ìˆìŠµë‹ˆë‹¤:")
            for pos in diagonal_invalid_positions:
                st.write(f"ìœ„ì¹˜: {pos[:2]}, ê°’: {pos[2]}")
        else:
            st.write("ëª¨ë“  ëŒ€ê° ì›ì†Œê°€ 1ë³´ë‹¤ í½ë‹ˆë‹¤.")



        with st.sidebar.expander('Leontief ê³¼ì • matrices'):
            leontief_files = {
            "normalization_denominator": st.session_state['normalization_denominator'],
            "íˆ¬ì…ê³„ìˆ˜í–‰ë ¬": st.session_state['df_normalized_with_label'],
            "leontief inverse": st.session_state['df_for_leontief_with_label'],
            "FL-BL": st.session_state['fl_bl'],
            "GDP": st.session_state['gdp_by_industry'],
            "ë¶€ê°€ê°€ì¹˜ìœ ë°œíš¨ê³¼": st.session_state['va_multiplier_by_sector'],
            "ë¶€ê°€ê°€ì¹˜ê³„ìˆ˜í–‰ë ¬": st.session_state['df_for_r_with_label'],
            "ë¶€ê°€ê°€ì¹˜ê³„ë²¡í„°": st.session_state['added_value_denominator']
            }
            download_multiple_csvs_as_zip(leontief_files, zip_name="Leontief ê³¼ì • ì „ì²´(zip)")
            donwload_data(st.session_state['normalization_denominator'], 'normailization denominator')
            donwload_data(st.session_state['df_normalized_with_label'], 'íˆ¬ì…ê³„ìˆ˜í–‰ë ¬')
            donwload_data(st.session_state['df_for_leontief_with_label'], 'leontief inverse')
            donwload_data(st.session_state['fl_bl'], 'FL-BL')
            donwload_data(st.session_state['gdp_by_industry'], 'GDP')
            donwload_data(st.session_state['va_multiplier_by_sector'], 'ë¶€ê°€ê°€ì¹˜ìœ ë°œíš¨ê³¼')
            donwload_data(st.session_state['df_for_r_with_label'], 'ë¶€ê°€ê°€ì¹˜ê³„ìˆ˜í–‰ë ¬')
            donwload_data(st.session_state['added_value_denominator'], 'ë¶€ê°€ê°€ì¹˜ê³„ë²¡í„°')


        st.subheader("FL-BL Plot")

        # -----------------------------
        # 1) ids_values ë§Œë“¤ê¸° + (ì¤‘ë³µ ì œê±°, ìˆœì„œ ìœ ì§€)
        # -----------------------------
        ids_values = [item for sublist in st.session_state.ids_simbol.values() for item in sublist]

        seen = set()
        ids_unique = []
        for x in ids_values:
            if x not in seen:
                seen.add(x)
                ids_unique.append(x)

        # -----------------------------
        # 2) í† ê¸€ì„ "í•œ í–‰"ì— ì „ë¶€ ë°°ì¹˜ (ê° ì•„ì´í…œë³„ í† ê¸€)
        #    - ê¸°ë³¸ê°’ True (ì „ë¶€ ON)
        # -----------------------------
        if len(ids_unique) > 0:
            cols = st.columns(len(ids_unique))  # âœ… í•œ ì¤„ì— ì „ë¶€
            selected_ids = []
            for i, name in enumerate(ids_unique):
                # keyëŠ” ì•ˆì „í•˜ê²Œ(íŠ¹ìˆ˜ë¬¸ì ì œê±°) + i ë¶™ì—¬ì„œ ì¤‘ë³µ ë°©ì§€
                safe = re.sub(r"[^0-9a-zA-Zê°€-í£_]", "_", str(name))
                key = f"hl_{i}_{safe}"

                with cols[i]:
                    if st.toggle(str(name), value=True, key=key):
                        selected_ids.append(name)
        else:
            selected_ids = []

        # -----------------------------
        # 3) DF ì¤€ë¹„ (ì²« í–‰ ì œê±°ëŠ” í†µì¼)
        # -----------------------------
        df = st.session_state['fl_bl'].copy()
        df = df.iloc[1:, :]

        highlight_df = df[df[1].isin(selected_ids)]

        # -----------------------------
        # 4) Plot: ì „ì²´ëŠ” other ìŠ¤íƒ€ì¼ë¡œ ê·¸ë¦¬ê³ ,
        #         í† ê¸€ ONì¸ ì• ë“¤ë§Œ ë¹¨ê°„ + ë¼ë²¨ overlay
        # -----------------------------
        fig, ax = plt.subplots(figsize=(12, 10))

        # ì „ì²´ ê¸°ë³¸ ì  (other ìŠ¤íƒ€ì¼)
        ax.scatter(df['2'], df['3'], facecolors='none', edgecolors='black', s=100)

        # ì„ íƒëœ ì• ë“¤ë§Œ ê°•ì¡° + ë¼ë²¨
        if not highlight_df.empty:
            ax.scatter(highlight_df['2'], highlight_df['3'], color='red', s=150)
            for _, row in highlight_df.iterrows():
                ax.text(row['2'], row['3'], row[1], color='black', fontsize=16, ha='right')

        ax.set_xlabel('FL', fontsize=14)
        ax.set_ylabel('BL', fontsize=14)
        ax.axhline(1, color='black', linestyle='--', linewidth=1)
        ax.axvline(1, color='black', linestyle='--', linewidth=1)

        st.pyplot(fig)


        # ì‚¬ì´ë“œë°” expander ì— ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì¶”ê°€
        with st.sidebar.expander("Plot ë‹¤ìš´ë¡œë“œ"):
            buf = io.BytesIO()
            # PNG í¬ë§·ìœ¼ë¡œ ë²„í¼ì— ì €ì¥
            fig.savefig(buf, format="png", bbox_inches="tight")
            buf.seek(0)
            st.download_button(
                label="Plot ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ",
                data=buf,
                file_name="fl_bl_plot.png",
                mime="image/png"
            )

        win_A = st.session_state['df_normalized_with_label'].iloc[2:, 2:].copy().values
        win_epsilon = 0.05

        win_N0 = compute_leontief_inverse(win_A, epsilon=win_epsilon)

        win_Diagon, win_N = separate_diagonals(win_N0)

        st.markdown("---")
        st.subheader("2. ë„¤íŠ¸ì›Œí¬ ì¶”ì¶œ ë°©ì‹ ì„ íƒ")

        # --------------------------------------------------------------------------------
        # [Step 1] ì´ˆê¸°í™” í•¨ìˆ˜ ì •ì˜
        # ë¼ë””ì˜¤ ë²„íŠ¼(ë©”ì†Œë“œ)ì´ ë³€ê²½ë  ë•Œ í˜¸ì¶œë˜ì–´, í•˜ë‹¨ ê²°ê³¼ì°½ì˜ ìƒíƒœ(state)ë¥¼ ì§€ì›Œë²„ë¦½ë‹ˆë‹¤.
        # --------------------------------------------------------------------------------
        def reset_threshold_state():
            # '2. filtering ê²°ê³¼' ì„¹ì…˜ì„ ì œì–´í•˜ëŠ” í•µì‹¬ ë³€ìˆ˜ë“¤ ì‚­ì œ
            keys_to_remove = ['threshold', 'threshold_cal']
            for key in keys_to_remove:
                if key in st.session_state:
                    del st.session_state[key]

        # ---------------------------------------------------------------------
        # 1. [Pre-calculation] ë‘ ê°€ì§€ ë°©ì‹ ë¯¸ë¦¬ ê³„ì‚° ë° ì„¸ì…˜ ì €ì¥
        # ---------------------------------------------------------------------
        
        # ë°©ì‹ 1: threshold_count (ê¸°ì¡´: ìµœì  ì„ê³„ê°’ ê³„ì‚°) ê²°ê³¼ ì €ì¥ (Float + Fig + Text)
        if 'res_method1_threshold' not in st.session_state:
            with st.spinner("Method 1 (Distance/Connectivity) ê³„ì‚° ì¤‘..."):
                # functions.pyì˜ threshold_count í•¨ìˆ˜ í˜¸ì¶œ (ì„ê³„ê°’ float, fig, text ë°˜í™˜)
                val, fig, txt = threshold_count(win_N)
                st.session_state['res_method1_threshold'] = val
                st.session_state['res_method1_fig'] = fig
                st.session_state['res_method1_text'] = txt

        # ë°©ì‹ 2: threshold_count_2 (ì‹ ê·œ: ë¬´í•œê¸‰ìˆ˜ Method A) ê²°ê³¼ ì €ì¥ (Matrix + Fig + Text)
        if 'res_method2_matrix' not in st.session_state:
            with st.spinner("Method 2 (Infinite Series) ê³„ì‚° ì¤‘..."):
                # functions.pyì˜ threshold_count_2 í•¨ìˆ˜ í˜¸ì¶œ (í–‰ë ¬ ndarray, fig, text ë°˜í™˜)
                mat, fig, txt = threshold_count_2(win_N)
                st.session_state['res_method2_matrix'] = mat
                st.session_state['res_method2_fig'] = fig
                st.session_state['res_method2_text'] = txt

        # ---------------------------------------------------------------------
        # [Persistent Display] ë¯¸ë¦¬ ê³„ì‚°ëœ ê²°ê³¼ ìš”ì•½ í‘œì‹œ (í•­ìƒ í‘œì‹œ)
        # ---------------------------------------------------------------------
        st.subheader("2. ë„¤íŠ¸ì›Œí¬ ì¶”ì¶œ ë°©ì‹ ì„ íƒ ë° ë¶„ì„ ìš”ì•½")
        
        # Method 1 ê²°ê³¼ í‘œì‹œ
        if 'res_method1_fig' in st.session_state:
            with st.expander("Method 1 ë¶„ì„ ê²°ê³¼ (Threshold Optimization)", expanded=True):
                st.pyplot(st.session_state['res_method1_fig'])
                st.markdown(st.session_state['res_method1_text'])

        # Method 2 (Method A) ê²°ê³¼ í‘œì‹œ
        if 'res_method2_fig' in st.session_state:
            with st.expander("Method 2 ë¶„ì„ ê²°ê³¼ (Infinite Series)", expanded=True):
                st.pyplot(st.session_state['res_method2_fig'])
                st.markdown(st.session_state['res_method2_text'])
        
        # ---------------------------------------------------------------------
        # 3. [Parameter Selection] ì‚¬ìš©ì ì„ íƒ
        # ---------------------------------------------------------------------
        method_option = st.radio(
            "ë¶„ì„ ëª¨ë“œ ì„ íƒ",
            [
                "Method 1: ìµœì  ì„ê³„ê°’ (Threshold Optimization)", 
                "Method 2: ë¬´í•œê¸‰ìˆ˜ ìˆ˜ë ´ (Series Expansion)"
            ],
            index=0,
            on_change=reset_threshold_state,  # <--- [í•µì‹¬] ê°’ì´ ë°”ë€Œë©´ ìœ„ í•¨ìˆ˜ ì‹¤í–‰ -> ê²°ê³¼ ì´ˆê¸°í™”
            help="Method 1ì€ ê±°ë¦¬ ìµœì†Œí™” ë° ì—°ê²°ì„± ê¸°ë°˜ìœ¼ë¡œ ì„ê³„ê°’ì„ ì°¾ìŠµë‹ˆë‹¤. Method 2ëŠ” ì •ë³´ëŸ‰ ë³€í™”ìœ¨ì´ ìˆ˜ë ´í•  ë•Œê¹Œì§€ ë„¤íŠ¸ì›Œí¬ë¥¼ í™•ì¥í•©ë‹ˆë‹¤."
        )

        # ---------------------------------------------------------------------
        # 3. [Standardization] ì„ íƒì— ë”°ë¼ 'final_network_matrix' ê²°ì •
        # ---------------------------------------------------------------------
        final_network_matrix = None

        if method_option.startswith("Method 1"):
            # Method 1 ë¡œì§ì€ í•˜ë‹¨ "2. ì•„ë˜ëŠ” ì„ê³„ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ filtering ê²°ê³¼" ì„¹ì…˜ì—ì„œ ì²˜ë¦¬ë©ë‹ˆë‹¤.
            pass

        else:
            # -----------------------------------------------------------------
            # [Method 2] Infinite Series
            # -----------------------------------------------------------------
            st.info("ğŸ“Š **Method 2 ë¶„ì„ ê²°ê³¼**")
            st.write("ğŸ”¹ ì´ ë°©ì‹ì€ ë¬´í•œê¸‰ìˆ˜ ìˆ˜ë ´ì„ í†µí•´ **ìë™ìœ¼ë¡œ ìƒì„±ëœ í–‰ë ¬**ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            st.caption("ğŸ‘‰ ë³„ë„ì˜ ì„ê³„ê°’ ì¡°ì • ì—†ì´, êµ¬ì¡°ì ìœ¼ë¡œ ì—°ê²°ëœ ë„¤íŠ¸ì›Œí¬ë¥¼ ê·¸ëŒ€ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.")

            # Method 2ëŠ” ê²°ê³¼ ìì²´ê°€ í–‰ë ¬ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ í• ë‹¹
            final_network_matrix = st.session_state['res_method2_matrix'].copy()
            st.session_state.delta = 0.0

        # ---------------------------------------------------------------------
        # 4. [Common Output] ê²°ê³¼ í†µí•© ë° ì‹œê°í™” (ê³µí†µ ë¡œì§)
        # ---------------------------------------------------------------------
        
        if final_network_matrix is not None:
            # ---------------------------------------------------------------------
            # 4. [Common Output] ê²°ê³¼ í†µí•© ë° ì‹œê°í™” (ê³µí†µ ë¡œì§)
            # ---------------------------------------------------------------------
            
            # (1) Binary Matrix ìƒì„± (0ë³´ë‹¤ í¬ë©´ 1, ì•„ë‹ˆë©´ 0)
            binary_matrix = (final_network_matrix > 0).astype(int)

            # (2) DataFrame ë§¤í•‘ (ì‹œê°í™” ë° ë‹¤ìš´ë¡œë“œìš©)
            # ë ˆì´ë¸”ì´ ìˆëŠ” í˜•íƒœ ìœ ì§€ë¥¼ ìœ„í•´ ê¸°ì¡´ df êµ¬ì¡° ì‚¬ìš© (df_normalized_with_label ê»ë°ê¸° ë³µì‚¬)
            
            filtered_matrix_df = st.session_state['df_normalized_with_label'].copy()
            filtered_matrix_df.iloc[2:, 2:] = final_network_matrix
            
            binary_matrix_df = st.session_state['df_normalized_with_label'].copy()
            binary_matrix_df.iloc[2:, 2:] = binary_matrix

            # (3) ê²°ê³¼ í‘œì‹œ
            st.write(f"**í˜„ì¬ ì ìš©ëœ ë„¤íŠ¸ì›Œí¬:** {method_option}")
            
            col_res1, col_res2 = st.tabs(["ê°€ì¤‘ì¹˜ ë„¤íŠ¸ì›Œí¬(Weighted)", "ì´ì§„ ë„¤íŠ¸ì›Œí¬(Binary)"])
            with col_res1:
                st.dataframe(filtered_matrix_df)
            with col_res2:
                st.dataframe(binary_matrix_df)

            # ---------------------------------------------------------------------
            # 5. [Downstream] ê·¸ë˜í”„ ìƒì„± (NetworkX) - ê¸°ì¡´ ë¡œì§ ì—°ê²°ìš©
            # ---------------------------------------------------------------------
            # G_tn: Weighted Graph
            G_tn = nx.DiGraph()
            all_nodes_tn = set(range(final_network_matrix.shape[0]))
            G_tn.add_nodes_from(all_nodes_tn)
            
            rows_tn, cols_tn = np.where(final_network_matrix > 0)
            weights_tn = final_network_matrix[rows_tn, cols_tn]
            edges_tn = [(j, i, {'weight': w}) for i, j, w in zip(rows_tn, cols_tn, weights_tn)]
            G_tn.add_edges_from(edges_tn)
            G_n = G_tn # Alias for downstream compatibility

            # G_bn: Binary Graph
            G_bn = nx.DiGraph()
            G_bn.add_nodes_from(all_nodes_tn)
            rows_bn, cols_bn = np.where(binary_matrix > 0)
            edges_bn = [(j, i) for i, j in zip(rows_bn, cols_bn)]
            G_bn.add_edges_from(edges_bn)

            # 3. ì¤‘ì•™ì„± ê³„ì‚° (ê¸°ì¡´ ë¡œì§ ë³µì›)
            n_df_degree, n_df_bc, n_df_cc, n_df_ev, n_df_hi, n_df_kim, n_gd_in_mean, n_gd_in_std, n_gd_out_mean, n_gd_out_std, n_bc_mean, n_bc_std, n_cc_in_mean, n_cc_in_std, n_cc_out_mean, n_cc_out_std, n_ev_in_mean, n_ev_in_std, n_ev_out_mean, n_ev_out_std, n_hub_mean, n_hub_std, n_ah_mean, n_ah_std, n_const_mean,n_const_std, n_eff_mean, n_eff_std = calculate_network_centralities(G_n, st.session_state['df_normalized_with_label'],True)
            
            bn_df_degree, bn_df_bc, bn_df_cc, bn_df_ev, bn_df_hi, bn_df_kim, bn_gd_in_mean, bn_gd_in_std, bn_gd_out_mean, bn_gd_out_std, bn_bc_mean, bn_bc_std, bn_cc_in_mean, bn_cc_in_std, bn_cc_out_mean, bn_cc_out_std, bn_ev_in_mean, bn_ev_in_std, bn_ev_out_mean, bn_ev_out_std, bn_hub_mean, bn_hub_std, bn_ah_mean, bn_ah_std, bn_const_mean,bn_const_std, bn_eff_mean, bn_eff_std = calculate_network_centralities(G_bn, st.session_state['df_normalized_with_label'],False)

            # 4. UN ë° Label DataFrames ìƒì„± (ì‹œê°í™”ìš©)
            # BNì´ í™•ì‹¤íˆ ì¡´ì¬í•˜ëŠ” ë¸”ë¡ ë‚´ë¶€ì—ì„œ UN ìƒì„±
            BN = binary_matrix
            UN = create_undirected_network(BN)
            
            win_N_final_label = filtered_matrix_df
            win_BN_final_label = binary_matrix_df
            win_UN_final_label = st.session_state['df_normalized_with_label'].copy()
            win_UN_final_label.iloc[2:,2:]= UN

            # ---------------------------------------------------------------------
            # [Visualization] ê¸°ì¡´ ì‹œê°í™” ì½”ë“œ (Unindented)
            # ---------------------------------------------------------------------
            col1_net, col2_net, col3_net = st.tabs([f"ì„ê³„ì¹˜ ì ìš© í›„ ë„¤íŠ¸ì›Œí¬ í–‰ë ¬", 'ì´ì§„í™”ëœ ë°©í–¥ì„± ë„¤íŠ¸ì›Œí¬ (BN)', 'ë¬´ë°©í–¥ ì´ì§„ ë„¤íŠ¸ì›Œí¬ (UN)'])
            with col1_net:
                st.write(win_N_final_label)
                st.markdown("##### ì„ê³„ì¹˜ ì ìš© í›„ ë„¤íŠ¸ì›Œí¬ í–‰ë ¬ì˜ ì§€í‘œ")
                col1_n, col2_n, col3_n, col4_n, col5_n, col6_n = st.tabs([f"Degree Centrality", 'Betweenness Centrality',"Closeness Centrality", "Eigenvector Centrality", "Hub & Authority","constraints&efficiencies"])
                with col1_n:
                    st.dataframe(n_df_degree)
                    st.write("In-Degree: Mean =", n_gd_in_mean, ", Std =", n_gd_in_std)
                    st.write("Out-Degree: Mean =", n_gd_out_mean, ", Std =", n_gd_out_std)
                
                with col2_n:
                    st.dataframe(
                        n_df_bc,
                        column_config={'Betweenness Centrality': st.column_config.NumberColumn('Betweenness Centrality', format='%.12f')}
                    )
                    st.write("Betweenness Centrality: Mean =", n_bc_mean, ", Std =", n_bc_std)
                
                with col3_n:
                    st.dataframe(
                        n_df_cc,
                        column_config={
                            'Indegree_Closeness Centrality': st.column_config.NumberColumn('Indegree_Closeness Centrality', format='%.12f'),
                            'Outdegree_Closeness Centrality': st.column_config.NumberColumn('Outdegree_Closeness Centrality', format='%.12f')
                        }
                    )
                    st.write("Indegree Closeness Centrality: Mean =", n_cc_in_mean, ", Std =", n_cc_in_std)
                    st.write("Outdegree Closeness Centrality: Mean =", n_cc_out_mean, ", Std =", n_cc_out_std)
                
                with col4_n:
                    st.dataframe(
                        n_df_ev,
                        column_config={
                            'Indegree_Eigenvector Centrality': st.column_config.NumberColumn('Indegree_Eigenvector Centrality', format='%.12f'),
                            'Outdegree_Eigenvector Centrality': st.column_config.NumberColumn('Outdegree_Eigenvector Centrality', format='%.12f')
                        }
                    )
                    st.write("Indegree Eigenvector Centrality: Mean =", n_ev_in_mean, ", Std =", n_ev_in_std)
                    st.write("Outdegree Eigenvector Centrality: Mean =", n_ev_out_mean, ", Std =", n_ev_out_std)
                
                with col5_n:
                    st.dataframe(
                        n_df_hi,
                        column_config={
                            'HITS Hubs': st.column_config.NumberColumn('HITS Hubs', format='%.12f'),
                            'HITS Authorities': st.column_config.NumberColumn('HITS Authorities', format='%.12f')
                        }
                    )
                    st.write("HITS Hubs: Mean =", n_hub_mean, ", Std =", n_hub_std)
                    st.write("HITS Authorities: Mean =", n_ah_mean, ", Std =", n_ah_std)
                with col6_n:
                    st.dataframe(
                        n_df_kim,
                        column_config={
                            'Constraint factor': st.column_config.NumberColumn('Constraint factor', format='%.12f'),
                            'Efficiency factor': st.column_config.NumberColumn('Efficiency factor', format='%.12f')
                        }
                    )
                    st.write("Constraint factor: Mean =", n_const_mean, ", Std =", n_const_std)
                    st.write("Efficiency factor: Mean =", n_eff_mean, ", Std =", n_eff_std)

            with col2_net:
                st.write(win_BN_final_label)
                    # 1. ë…¸ë“œ ì´ë¦„(A, B, C01, ...) ë¦¬ìŠ¤íŠ¸ë¡œ ì¶”ì¶œ
                # win_BN_final_label ì˜ 2ë²ˆì§¸ ì—´(ì¸ë±ìŠ¤ 0)ì— ì‹¤ì œ ë…¸ë“œëª…ì´ ë“¤ì–´ìˆë‹¤ê³  ê°€ì •
                node_names_delta = win_BN_final_label.iloc[2:, 0].tolist()  

                # 3. ë ˆì´ì•„ì›ƒ ê³„ì‚°
                pos = nx.spring_layout(G_bn, seed=42)

                # 4. ì‹œê°í™”
                fig, ax = plt.subplots(figsize=(8, 6))
                nx.draw_networkx_nodes(G_bn, pos, node_size=400, ax=ax)
                nx.draw_networkx_edges(G_bn, pos, arrowstyle='->', arrowsize=10, ax=ax)

                # 5. ë ˆì´ë¸” ë§¤í•‘ (ë…¸ë“œ ë²ˆí˜¸ â†’ ì‹¤ì œ ì´ë¦„)
                label_dict = {i: name for i, name in enumerate(node_names_delta)}

                # 6. ë ˆì´ë¸” ê·¸ë¦¬ê¸°
                nx.draw_networkx_labels(G_bn, pos, labels=label_dict, font_size=10, ax=ax)

                ax.set_title("Delta-Thresholded Binary Network (DBN)", fontsize=14)
                ax.axis('off')
                st.pyplot(fig)




                st.markdown("##### ì´ì§„ ë°©í–¥ì„± ë„¤íŠ¸ì›Œí¬ í–‰ë ¬ì˜ ì§€í‘œ")
                col1_bn, col2_bn, col3_bn, col4_bn, col5_bn, col6_bn = st.tabs([f"Degree Centrality", 'Betweenness Centrality',"Closeness Centrality", "Eigenvector Centrality", "Hub & Authority", "constraints&efficiencies"])
                with col1_bn:
                    st.dataframe(bn_df_degree)
                    st.write("In-Degree: Mean =", bn_gd_in_mean, ", Std =", bn_gd_in_std)
                    st.write("Out-Degree: Mean =", bn_gd_out_mean, ", Std =", bn_gd_out_std)
                
                with col2_bn:
                    st.dataframe(
                        bn_df_bc,
                        column_config={'Betweenness Centrality': st.column_config.NumberColumn('Betweenness Centrality', format='%.12f')}
                    )
                    st.write("Betweenness Centrality: Mean =", bn_bc_mean, ", Std =", bn_bc_std)
                
                with col3_bn:
                    st.dataframe(
                        bn_df_cc,
                        column_config={
                            'Indegree_Closeness Centrality': st.column_config.NumberColumn('Indegree_Closeness Centrality', format='%.12f'),
                            'Outdegree_Closeness Centrality': st.column_config.NumberColumn('Outdegree_Closeness Centrality', format='%.12f')
                        }
                    )
                    st.write("Indegree Closeness Centrality: Mean =", bn_cc_in_mean, ", Std =", bn_cc_in_std)
                    st.write("Outdegree Closeness Centrality: Mean =", bn_cc_out_mean, ", Std =", bn_cc_out_std)
                
                with col4_bn:
                    st.dataframe(
                        bn_df_ev,
                        column_config={
                            'Indegree_Eigenvector Centrality': st.column_config.NumberColumn('Indegree_Eigenvector Centrality', format='%.12f'),
                            'Outdegree_Eigenvector Centrality': st.column_config.NumberColumn('Outdegree_Eigenvector Centrality', format='%.12f')
                        }
                    )
                    st.write("Indegree Eigenvector Centrality: Mean =", bn_ev_in_mean, ", Std =", bn_ev_in_std)
                    st.write("Outdegree Eigenvector Centrality: Mean =", bn_ev_out_mean, ", Std =", bn_ev_out_std)
                
                with col5_bn:
                    st.dataframe(
                        bn_df_hi,
                        column_config={
                            'HITS Hubs': st.column_config.NumberColumn('HITS Hubs', format='%.12f'),
                            'HITS Authorities': st.column_config.NumberColumn('HITS Authorities', format='%.12f')
                        }
                    )
                    st.write("HITS Hubs: Mean =", bn_hub_mean, ", Std =", bn_hub_std)
                    st.write("HITS Authorities: Mean =", bn_ah_mean, ", Std =", bn_ah_std)

                with col6_bn:
                    st.dataframe(
                        bn_df_kim,
                        column_config={
                            'Constraint factor': st.column_config.NumberColumn('Constraint factor', format='%.12f'),
                            'Efficiency factor': st.column_config.NumberColumn('Efficiency factor', format='%.12f')
                        }
                    )
                    st.write("Constraint factor: Mean =", bn_const_mean, ", Std =", bn_const_std)
                    st.write("Efficiency factor: Mean =", bn_eff_mean, ", Std =", bn_eff_std)

            with col3_net:
                st.write(win_UN_final_label)


            with st.sidebar.expander(f"filtered file(delta:{st.session_state.delta})"):
                delta_original = {
                "delta_original_degree_centrality": n_df_degree,
                "delta_original_betweenness_centrality": n_df_bc,
                "delta_original_closeness_centrality": n_df_cc,
                "delta_original_eigenvector_centrality": n_df_ev,
                "delta_original_hits": n_df_hi,
                "delta_original_constraints&efficiencies": n_df_kim
                                        }
                delta_bn = {
                "delta_bn_degree_centrality": bn_df_degree,
                "delta_bn_betweenness_centrality": bn_df_bc,
                "delta_bn_closeness_centrality": bn_df_cc,
                "delta_bn_eigenvector_centrality": bn_df_ev,
                "delta_bn_hits": bn_df_hi,
                "delta_bn_constraints&efficiencies": bn_df_kim
                                        }
                
                all_delta = {
                "filtered_matrix_X(delta)":          win_N_final_label,
                **delta_original,
                "binary_matrix(delta)":              win_BN_final_label,
                **delta_bn,
                "undirected_binary_matrix(delta)":   win_UN_final_label
                }

                download_multiple_csvs_as_zip(
                    all_delta,
                    zip_name="delta ì ìš© ì „ì²´ ê²°ê³¼ë“¤(zip)"
                )
                donwload_data(win_N_final_label, 'filtered_matrix_X(delta)')
                download_multiple_csvs_as_zip(delta_original, zip_name="delta ì ìš© ë„¤íŠ¸ì›Œí¬ì˜ ì§€í‘œë“¤(zip)")
                donwload_data(win_BN_final_label, 'binary_matrix(delta)')
                download_multiple_csvs_as_zip(delta_bn, zip_name="delta ì ìš© BN ë„¤íŠ¸ì›Œí¬ì˜ ì§€í‘œë“¤(zip)")
                donwload_data(win_UN_final_label, 'undirected_binary_matrix(delta)')




        if method_option.startswith("Method 1"):
            st.info("ğŸ“Š **Method 1 ë¶„ì„ ê²°ê³¼ (Threshold Filtering)**")
            st.write("ğŸ”¹ ì´ ë°©ì‹ì€ ì„ê³„ê°’(Threshold)ì„ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ìš”í•˜ì§€ ì•Šì€ ì—°ê²°ì„ ì œê±°í•˜ì—¬ í•µì‹¬ ë„¤íŠ¸ì›Œí¬ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.")
            st.caption("ğŸ‘‰ ì•„ë˜ ê·¸ë˜í”„ë¥¼ ì°¸ê³ í•˜ì—¬ ì ì ˆí•œ ì„ê³„ê°’ì„ ì„¤ì •í•˜ê³  'ë…¸ë“œ ìƒì¡´ë¹„ìœ¨'ì„ í™•ì¸í•˜ì„¸ìš”.")

            st.subheader('thresholdì— ë”°ë¥¸ ìƒì¡´ë¹„ìœ¨ ê·¸ë˜í”„')

            # ê·¸ë˜í”„ ê·¸ë¦¬ê¸° (ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì–´ ìˆë‹¤ê³  ê°€ì •)
            if 'df_for_leontief_with_label' in st.session_state:
                 # ì¸í„°ë™í‹°ë¸Œ ì„¹ì…˜: ê·¸ë˜í”„ì™€ í…ìŠ¤íŠ¸(ì¶”ì²œê°’) ëª¨ë‘ í‘œì‹œ
                 _, iter_fig, iter_txt = threshold_count(st.session_state['df_for_leontief_with_label'].iloc[2:, 2:])
                 st.pyplot(iter_fig) # ê·¸ë˜í”„ ì¶œë ¥
                 st.markdown(iter_txt) # ì¶”ì²œ ì„ê³„ê°’ í…ìŠ¤íŠ¸ ì¶œë ¥

            col1, col2 = st.columns(2)
            with col1:
                # í…ìŠ¤íŠ¸ ì…ë ¥ì°½ (ì—¬ê¸°ì„œ ì…ë ¥ë°›ì€ ê°’ì€ ë²„íŠ¼ ëˆ„ë¥´ê¸° ì „ê¹Œì§€ëŠ” ì§€ì—­ë³€ìˆ˜ì—ë§Œ ì €ì¥ë¨)
                input_val = st.text_input('thresholdë¥¼ ì…ë ¥í•˜ì„¸ìš”', '0.000') 
                threshold_val = float(input_val) if input_val else 0.0

            with col2:
                if st.button('Apply threshold'):
                    # ë²„íŠ¼ì„ ëˆŒëŸ¬ì•¼ë§Œ ë¹„ë¡œì†Œ session_stateì— ë“±ë¡ë˜ì–´ ì•„ë˜ ê²°ê³¼ì°½ì´ ì—´ë¦¼
                    st.session_state.threshold = threshold_val
                    st.session_state.threshold_cal = True


        if 'threshold' in st.session_state and st.session_state.show_edited:
            if st.session_state.threshold_cal:
                # binary matrix ìƒì„±
                binary_matrix = make_binary_matrix(st.session_state['df_for_leontief_with_label'].iloc[2:, 2:].apply(pd.to_numeric, errors='coerce'), st.session_state.threshold)
                _, binary_matrix = separate_diagonals(binary_matrix)
                binary_matrix_with_label = st.session_state['df_for_leontief'].copy()
                binary_matrix_with_label.iloc[2:,2:] = binary_matrix


                filtered_matrix_X = st.session_state['df_for_leontief'].copy()
                filtered_matrix_X.iloc[2:, 2:] = filtered_matrix_X.iloc[2:, 2:].apply(pd.to_numeric, errors='coerce')*binary_matrix

                filtered_normalized = st.session_state['df_normalized_with_label']
                filtered_normalized.iloc[2:, 2:] = st.session_state['df_normalized_with_label'].iloc[2:, 2:].apply(pd.to_numeric, errors='coerce')*binary_matrix

                filtered_leontief = st.session_state['df_for_leontief_with_label']
                filtered_leontief.iloc[2:, 2:] = st.session_state['df_for_leontief_with_label'].iloc[2:, 2:].apply(pd.to_numeric, errors='coerce')*binary_matrix

                G_tn = nx.DiGraph()

                # ëª¨ë“  ë…¸ë“œ ê°€ì ¸ì˜¤ê¸° (ê³ ë¦½ëœ ë…¸ë“œ í¬í•¨)
                all_nodes_tn = set(range(filtered_leontief.iloc[2:, 2:].shape[0]))
                G_tn.add_nodes_from(all_nodes_tn)  # ëª¨ë“  ë…¸ë“œ ì¶”ê°€ (ê³ ë¦½ ë…¸ë“œ í¬í•¨)

                rows_tn, cols_tn = np.where(filtered_leontief.iloc[2:, 2:] != 0)
                weights_tn = filtered_leontief.iloc[2:, 2:].to_numpy()[rows_tn, cols_tn]
                edges_tn = [(j, i, {'weight': w}) for i, j, w in zip(rows_tn, cols_tn, weights_tn)]
                G_tn.add_edges_from(edges_tn)


                tn_df_degree, tn_df_bc, tn_df_cc, tn_df_ev, tn_df_hi,tn_df_kim, tn_gd_in_mean, tn_gd_in_std, tn_gd_out_mean, tn_gd_out_std, tn_bc_mean, tn_bc_std, tn_cc_in_mean, tn_cc_in_std, tn_cc_out_mean, tn_cc_out_std, tn_ev_in_mean, tn_ev_in_std, tn_ev_out_mean, tn_ev_out_std, tn_hub_mean, tn_hub_std, tn_ah_mean, tn_ah_std, tn_const_mean,tn_const_std, tn_eff_mean, tn_eff_std = calculate_network_centralities(G_tn, st.session_state['df_normalized_with_label'],True)
                
                tbn_df_degree, tbn_df_bc, tbn_df_cc, tbn_df_ev, tbn_df_hi,tbn_df_kim, tbn_gd_in_mean, tbn_gd_in_std, tbn_gd_out_mean, tbn_gd_out_std, tbn_bc_mean, tbn_bc_std, tbn_cc_in_mean, tbn_cc_in_std, tbn_cc_out_mean, tbn_cc_out_std, tbn_ev_in_mean, tbn_ev_in_std, tbn_ev_out_mean, tbn_ev_out_std, tbn_hub_mean, tbn_hub_std, tbn_ah_mean, tbn_ah_std, tbn_const_mean, tbn_const_std, tbn_eff_mean, tbn_eff_std = calculate_network_centralities(G_tn, st.session_state['df_normalized_with_label'],False)

            # [UI Style Matching] Common Outputê³¼ ìœ ì‚¬í•œ êµ¬ì¡°ë¡œ ë³€ê²½
            st.write(f"**í˜„ì¬ ì ìš©ëœ ì„ê³„ê°’:** {st.session_state.threshold}")
            
            col_res1, col_res2 = st.tabs(["ê°€ì¤‘ì¹˜ ë„¤íŠ¸ì›Œí¬(Weighted)", "ì´ì§„ ë„¤íŠ¸ì›Œí¬(Binary)"])
            with col_res1:
                st.dataframe(filtered_leontief)
            with col_res2:
                st.dataframe(binary_matrix_with_label)

            st.subheader('Threshold ì ìš© í›„ Filtered matrices ìƒì„¸ ë¶„ì„')

            col1, col2, col3, col4 = st.tabs(['Filtered_leontief (Raw)', 'Binary_matrix (Raw)','Filtered_matrix (Raw)','Filtered_Normalized (Raw)'])
            with col1:
                st.write(filtered_leontief)
                st.markdown("##### Threshold ì ìš© í›„ ë„¤íŠ¸ì›Œí¬ í–‰ë ¬ì˜ ì§€í‘œ")
                col1_tn, col2_tn, col3_tn, col4_tn, col5_tn, col6_tn = st.tabs([f"Degree Centrality", 'Betweenness Centrality',"Closeness Centrality", "Eigenvector Centrality", "Hub & Authority", 'constraints&efficiencies'])
                with col1_tn:
                    st.dataframe(tn_df_degree)
                    st.write("In-Degree: Mean =", tn_gd_in_mean, ", Std =", tn_gd_in_std)
                    st.write("Out-Degree: Mean =", tn_gd_out_mean, ", Std =", tn_gd_out_std)
                
                with col2_tn:
                    st.dataframe(
                        tn_df_bc,
                        column_config={'Betweenness Centrality': st.column_config.NumberColumn('Betweenness Centrality', format='%.12f')}
                    )
                    st.write("Betweenness Centrality: Mean =", tn_bc_mean, ", Std =", tn_bc_std)
                
                with col3_tn:
                    st.dataframe(
                        tn_df_cc,
                        column_config={
                            'Indegree_Closeness Centrality': st.column_config.NumberColumn('Indegree_Closeness Centrality', format='%.12f'),
                            'Outdegree_Closeness Centrality': st.column_config.NumberColumn('Outdegree_Closeness Centrality', format='%.12f')
                        }
                    )
                    st.write("Indegree Closeness Centrality: Mean =", tn_cc_in_mean, ", Std =", tn_cc_in_std)
                    st.write("Outdegree Closeness Centrality: Mean =", tn_cc_out_mean, ", Std =", tn_cc_out_std)
                
                with col4_tn:
                    st.dataframe(
                        tn_df_ev,
                        column_config={
                            'Indegree_Eigenvector Centrality': st.column_config.NumberColumn('Indegree_Eigenvector Centrality', format='%.12f'),
                            'Outdegree_Eigenvector Centrality': st.column_config.NumberColumn('Outdegree_Eigenvector Centrality', format='%.12f')
                        }
                    )
                    st.write("Indegree Eigenvector Centrality: Mean =", tn_ev_in_mean, ", Std =", tn_ev_in_std)
                    st.write("Outdegree Eigenvector Centrality: Mean =", tn_ev_out_mean, ", Std =", tn_ev_out_std)
                
                with col5_tn:
                    st.dataframe(
                        tn_df_hi,
                        column_config={
                            'HITS Hubs': st.column_config.NumberColumn('HITS Hubs', format='%.12f'),
                            'HITS Authorities': st.column_config.NumberColumn('HITS Authorities', format='%.12f')
                        }
                    )
                    st.write("HITS Hubs: Mean =", tn_hub_mean, ", Std =", tn_hub_std)
                    st.write("HITS Authorities: Mean =", tn_ah_mean, ", Std =", tn_ah_std)

                with col6_tn:
                    st.dataframe(
                        tn_df_kim,
                        column_config={
                            'Constraint factor': st.column_config.NumberColumn('Constraint factor', format='%.12f'),
                            'Efficiency factor': st.column_config.NumberColumn('Efficiency factor', format='%.12f')
                        }
                    )
                    st.write("Constraint factor: Mean =", tn_const_mean, ", Std =", tn_const_std)
                    st.write("Efficiency factor: Mean =", tn_eff_mean, ", Std =", tn_eff_std)

            with col2:
                st.write(binary_matrix_with_label)
                # 1. ë…¸ë“œ ì´ë¦„(A, B, C01, ...) ë¦¬ìŠ¤íŠ¸ë¡œ ì¶”ì¶œ
                #    binary_matrix_with_label ì˜ 2ë²ˆì§¸ í–‰ë¶€í„° ì²« ë²ˆì§¸ ì—´(0ë²ˆ) ê°’ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
                node_names_tn = binary_matrix_with_label.iloc[2:, 0].tolist()

                # 2. ë ˆì´ì•„ì›ƒ ê³„ì‚°
                pos_tn = nx.spring_layout(G_tn, seed=42)

                # 3. ì‹œê°í™”
                fig_tn, ax_tn = plt.subplots(figsize=(8, 6))
                nx.draw_networkx_nodes(G_tn, pos_tn, node_size=400, ax=ax_tn)
                nx.draw_networkx_edges(G_tn, pos_tn, arrowstyle='->', arrowsize=10, ax=ax_tn)

                # 4. ë ˆì´ë¸” ë§¤í•‘ (ë…¸ë“œ ë²ˆí˜¸ â†’ ì‹¤ì œ ì´ë¦„)
                label_dict_tn = {i: name for i, name in enumerate(node_names_tn)}

                # 5. ë ˆì´ë¸” ê·¸ë¦¬ê¸°
                nx.draw_networkx_labels(G_tn, pos_tn, labels=label_dict_tn, font_size=10, ax=ax_tn)

                ax_tn.set_title("Thresholded Binary Network (TBN)", fontsize=14)
                ax_tn.axis('off')
                st.pyplot(fig_tn)

                st.markdown("##### ì´ì§„ ë°©í–¥ì„± ë„¤íŠ¸ì›Œí¬ í–‰ë ¬ì˜ ì§€í‘œ")
                col1_tbn, col2_tbn, col3_tbn, col4_tbn, col5_tbn, col6_tbn = st.tabs([f"Degree Centrality", 'Betweenness Centrality',"Closeness Centrality", "Eigenvector Centrality", "Hub & Authority", "constraints&efficiencies"])
                with col1_tbn:
                    st.dataframe(tbn_df_degree)
                    st.write("In-Degree: Mean =", tbn_gd_in_mean, ", Std =", tbn_gd_in_std)
                    st.write("Out-Degree: Mean =", tbn_gd_out_mean, ", Std =", tbn_gd_out_std)
                
                with col2_tbn:
                    st.dataframe(
                        tbn_df_bc,
                        column_config={'Betweenness Centrality': st.column_config.NumberColumn('Betweenness Centrality', format='%.12f')}
                    )
                    st.write("Betweenness Centrality: Mean =", tbn_bc_mean, ", Std =", tbn_bc_std)
                
                with col3_tbn:
                    st.dataframe(
                        tbn_df_cc,
                        column_config={
                            'Indegree_Closeness Centrality': st.column_config.NumberColumn('Indegree_Closeness Centrality', format='%.12f'),
                            'Outdegree_Closeness Centrality': st.column_config.NumberColumn('Outdegree_Closeness Centrality', format='%.12f')
                        }
                    )
                    st.write("Indegree Closeness Centrality: Mean =", tbn_cc_in_mean, ", Std =", tbn_cc_in_std)
                    st.write("Outdegree Closeness Centrality: Mean =", tbn_cc_out_mean, ", Std =", tbn_cc_out_std)
                
                with col4_tbn:
                    st.dataframe(
                        tbn_df_ev,
                        column_config={
                            'Indegree_Eigenvector Centrality': st.column_config.NumberColumn('Indegree_Eigenvector Centrality', format='%.12f'),
                            'Outdegree_Eigenvector Centrality': st.column_config.NumberColumn('Outdegree_Eigenvector Centrality', format='%.12f')
                        }
                    )
                    st.write("Indegree Eigenvector Centrality: Mean =", tbn_ev_in_mean, ", Std =", tbn_ev_in_std)
                    st.write("Outdegree Eigenvector Centrality: Mean =", tbn_ev_out_mean, ", Std =", tbn_ev_out_std)
                
                with col5_tbn:
                    st.dataframe(
                        tbn_df_hi,
                        column_config={
                            'HITS Hubs': st.column_config.NumberColumn('HITS Hubs', format='%.12f'),
                            'HITS Authorities': st.column_config.NumberColumn('HITS Authorities', format='%.12f')
                        }
                    )
                    st.write("HITS Hubs: Mean =", tbn_hub_mean, ", Std =", tbn_hub_std)
                    st.write("HITS Authorities: Mean =", tbn_ah_mean, ", Std =", tbn_ah_std)

                with col6_tbn:
                    st.dataframe(
                        tbn_df_kim,
                        column_config={
                            'Constraint factor': st.column_config.NumberColumn('Constraint factor', format='%.12f'),
                            'Efficiency factor': st.column_config.NumberColumn('Efficiency factor', format='%.12f')
                        }
                    )
                    st.write("Constraint factor: Mean =", tbn_const_mean, ", Std =", tbn_const_std)
                    st.write("Efficiency factor: Mean =", tbn_eff_mean, ", Std =", tbn_eff_std)
            with col3:
                st.write(filtered_matrix_X)
            with col4:
                st.write(filtered_normalized)


            with st.sidebar.expander(f"filtered file(threshold:{st.session_state.threshold})"):
                threshold_original = {
                "threshold_original_degree_centrality": tn_df_degree,
                "threshold_original_betweenness_centrality": tn_df_bc,
                "threshold_original_closeness_centrality": tn_df_cc,
                "threshold_original_eigenvector_centrality": tn_df_ev,
                "threshold_original_hits": tn_df_hi,
                "threshold_original_constraints&efficiencies": tn_df_kim
                                        }
                threshold_bn = {
                "threshold_bn_degree_centrality": tbn_df_degree,
                "threshold_bn_betweenness_centrality": tbn_df_bc,
                "threshold_bn_closeness_centrality": tbn_df_cc,
                "threshold_bn_eigenvector_centrality": tbn_df_ev,
                "threshold_bn_hits": tbn_df_hi,
                "threshold_bn_constraints&efficiencies": tbn_df_kim
                                        }
                
                # ëª¨ë“  ê²°ê³¼ë¥¼ í•œ dictìœ¼ë¡œ í•©ì¹˜ê¸°
                all_threshold = {
                    "filtered_leontief(threshold)":        filtered_leontief,
                    **threshold_original,
                    "binary_matrix(threshold)":            binary_matrix_with_label,
                    **threshold_bn,
                    "filtered_matrix_X(threshold)":        filtered_matrix_X,
                    "filtered_normalized(threshold)":      filtered_normalized
                }
                # ZIPìœ¼ë¡œ í•œ ë²ˆì— ë‹¤ìš´ë¡œë“œ
                download_multiple_csvs_as_zip(
                    all_threshold,
                    zip_name="threshold ì ìš© ì „ì²´ ê²°ê³¼ë“¤(zip)"
                )
                donwload_data(filtered_leontief, 'filtered_leontief(threshold)')
                download_multiple_csvs_as_zip(threshold_original, zip_name="threshold ì ìš© ë„¤íŠ¸ì›Œí¬ì˜ ì§€í‘œë“¤(zip)")
                donwload_data(binary_matrix_with_label, 'binary_matrix(threshold)')
                download_multiple_csvs_as_zip(threshold_bn, zip_name="threshold ì ìš© BN ë„¤íŠ¸ì›Œí¬ì˜ ì§€í‘œë“¤(zip)")
                donwload_data(filtered_matrix_X, 'filtered_matrix_X(threshold)')
                donwload_data(filtered_normalized, 'filtered_normalized(threshold)')

    
            # [ê³µí†µ] í•„ìš”í•œ ê³³ì— í•œ ë²ˆë§Œ ë„£ì–´ ë‘ì„¸ìš”
    def _gather_all_dataframes() -> dict[str, pd.DataFrame]:
        """session_state ì•ˆì— ì¡´ì¬í•˜ëŠ” ëª¨ë“  DataFrameì„ í•œ ZIPìœ¼ë¡œ ë¬¶ì„ dict ìƒì„±"""
        dfs: dict[str, pd.DataFrame] = {}

        # 1) ìµœì´ˆ ì—…ë¡œë“œ ì›ë³¸
        if 'df' in st.session_state:
            dfs['uploaded_df']          = st.session_state['df']
            if 'mid_ID_idx' in st.session_state:
                dfs['uploaded_matrix_X'] = get_submatrix_withlabel(
                    st.session_state['df'], first_idx[0], first_idx[1],
                    st.session_state['mid_ID_idx'][0], st.session_state['mid_ID_idx'][1],
                    first_idx, numberoflabel=number_of_label)
                dfs['uploaded_matrix_R'] = get_submatrix_withlabel(
                    st.session_state['df'], st.session_state['mid_ID_idx'][0]+1, first_idx[1],
                    st.session_state['df'].shape[0]-1, st.session_state['mid_ID_idx'][1],
                    first_idx, numberoflabel=number_of_label)
                dfs['uploaded_matrix_C'] = get_submatrix_withlabel(
                    st.session_state['df'], first_idx[0], st.session_state['mid_ID_idx'][1]+1,
                    st.session_state['mid_ID_idx'][0], st.session_state['df'].shape[1]-1,
                    first_idx, numberoflabel=number_of_label)

        # 2) í¸ì§‘ ì™„ë£Œë³¸
        if 'df_edited' in st.session_state and 'edited_matrix_X' in locals():
            dfs['edited_df']           = st.session_state['df_edited']
            dfs['edited_matrix_X']     = edited_matrix_X
            dfs['edited_matrix_R']     = edited_matrix_R
            dfs['edited_matrix_C']     = edited_matrix_C

        # 3) Leontief ê´€ë ¨
        if 'df_for_leontief_with_label' in st.session_state:
            dfs['íˆ¬ì…ê³„ìˆ˜í–‰ë ¬']             = st.session_state['df_normalized_with_label']
            dfs['leontief_inverse']        = st.session_state['df_for_leontief_with_label']
            dfs['FL_BL']                   = st.session_state['fl_bl']
            dfs['ë¶€ê°€ê°€ì¹˜ê³„ìˆ˜í–‰ë ¬']          = st.session_state['df_for_r_with_label']
            dfs['ë¶€ê°€ê°€ì¹˜ê³„ë²¡í„°']            = st.session_state['added_value_denominator']
            dfs['normalization_denominator'] = st.session_state['normalization_denominator']

        # 4) delta í•„í„° ê²°ê³¼
        if 'delta' in st.session_state and 'win_N_final_label' in locals(): 
            dfs['filtered_matrix_X(delta)']      = win_N_final_label
            dfs['binary_matrix(delta)']          = win_BN_final_label
            dfs['undirected_binary_matrix(delta)'] = win_UN_final_label
            dfs.update({                         # ì§€í‘œë“¤
                'delta_original_degree_centrality':      n_df_degree,
                'delta_original_betweenness_centrality': n_df_bc,
                'delta_original_closeness_centrality':   n_df_cc,
                'delta_original_eigenvector_centrality': n_df_ev,
                'delta_original_hits':                  n_df_hi,
                "delta_original_constraints&efficiencies": n_df_kim,
                'delta_bn_degree_centrality':           bn_df_degree,
                'delta_bn_betweenness_centrality':      bn_df_bc,
                'delta_bn_closeness_centrality':        bn_df_cc,
                'delta_bn_eigenvector_centrality':      bn_df_ev,
                'delta_bn_hits':                        bn_df_hi,
                "delta_bn_constraints&efficiencies":    bn_df_kim
            })

        # 5) threshold í•„í„° ê²°ê³¼
        if 'threshold' in st.session_state and 'binary_matrix_with_label' in locals():
            dfs['filtered_leontief(threshold)']   = filtered_leontief
            dfs['binary_matrix(threshold)']       = binary_matrix_with_label
            dfs['filtered_matrix_X(threshold)']   = filtered_matrix_X
            dfs['filtered_normalized(threshold)'] = filtered_normalized
            dfs.update({
                'threshold_original_degree_centrality':      tn_df_degree,
                'threshold_original_betweenness_centrality': tn_df_bc,
                'threshold_original_closeness_centrality':   tn_df_cc,
                'threshold_original_eigenvector_centrality': tn_df_ev,
                'threshold_original_hits':                  tn_df_hi,
                "threshold_original_constraints&efficiencies": tn_df_kim,
                'threshold_bn_degree_centrality':           tbn_df_degree,
                'threshold_bn_betweenness_centrality':      tbn_df_bc,
                'threshold_bn_closeness_centrality':        tbn_df_cc,
                'threshold_bn_eigenvector_centrality':      tbn_df_ev,
                'threshold_bn_hits':                        tbn_df_hi,
                "threshold_bn_constraints&efficiencies":    tbn_df_kim
            })

        return dfs
    with st.sidebar.expander("ì „ì²´ ê²°ê³¼ ZIP ë‹¤ìš´ë¡œë“œ"):
        all_dfs = _gather_all_dataframes()
        if all_dfs:
            download_multiple_csvs_as_zip(all_dfs, zip_name="IO_analysis_all_results(zip)")

        else:
            st.write("ì•„ì§ ì €ì¥ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë¶„ì„ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
    st.sidebar.header('ìˆ˜ì •ë‚´ì—­')
    with st.sidebar.expander('ìˆ˜ì •ë‚´ì—­ ë³´ê¸°'):
        st.text(st.session_state['data_editing_log'])

if __name__ == "__main__":
    main()
